import os
import pandas as pd
from langchain_core.tools import tool

# ì „ì—­ DataFrame ë³€ìˆ˜
_global_df = None

def set_dataframe(df: pd.DataFrame):
    """ì „ì—­ DataFrameì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    global _global_df
    _global_df = df

def get_dataframe() -> pd.DataFrame:
    """ì „ì—­ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _global_df
    if _global_df is None:
        raise ValueError("DataFrameì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dataframe()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    return _global_df

# DEPRECATED: get_sales_volume_by_division - replaced by smart_query_processor
# Use smart_query_processor for questions like "2023ë…„ ìŠ¤í…Œì¸ë¦¬ìŠ¤ì˜ ë§¤ì¶œìˆ˜ëŸ‰"

# DEPRECATED: get_total_sales_volume_by_division - replaced by smart_query_processor for specific divisions
# For "ì „ì²´" queries, use get_overall_summary() instead
# For specific divisions, use smart_query_processor("ìŠ¤í…Œì¸ë¦¬ìŠ¤ì˜ ë§¤ì¶œìˆ˜ëŸ‰")

@tool
def get_total_sales_volume_by_fund(fund_center: str) -> str:
    """íŠ¹ì • í€ë“œì„¼í„°(Funds Center)ì— ëŒ€í•œ ì „ì²´ ë§¤ì¶œìˆ˜ëŸ‰(M/T)ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    df = get_dataframe()
    filtered = df[df["FundsCenter"].str.contains(fund_center, na=False)]
    total = filtered["ë§¤ì¶œìˆ˜ëŸ‰(M/T)"].sum()
    return f"{fund_center}ì˜ ì´ ë§¤ì¶œìˆ˜ëŸ‰ì€ {total:,.0f} í†¤ì…ë‹ˆë‹¤."

@tool
def get_total_sales_volume_by_year(year: int) -> str:
    """íŠ¹ì • ì—°ë„(Period/Year)ì˜ ì „ì²´ ë§¤ì¶œìˆ˜ëŸ‰(M/T)ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    df = get_dataframe()
    filtered = df[df["Period/Year"].astype(str).str.contains(str(year))]
    total = filtered["ë§¤ì¶œìˆ˜ëŸ‰(M/T)"].sum()
    return f"{year}ë…„ ì „ì²´ ë§¤ì¶œìˆ˜ëŸ‰ì€ {total:,.0f} í†¤ì…ë‹ˆë‹¤."

# DEPRECATED: get_operating_profit_by_division - replaced by smart_query_processor
# Use smart_query_processor for questions like "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì˜ ì˜ì—…ì´ìµ"

# @tool
# def get_operating_profit_by_year(year: int) -> str:
#     """íŠ¹ì • ì—°ë„(Period/Year)ì˜ ì „ì²´ ì˜ì—…ì´ìµ(5.ì˜ì—…ì´ìµ)ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
#     df = get_dataframe()
#     filtered = df[df["Period/Year"].astype(str).str.contains(str(year))]
#     total = filtered["5.ì˜ì—…ì´ìµ"].sum()
#     return f"{year}ë…„ì˜ ì „ì²´ ì˜ì—…ì´ìµì€ {total:,.0f}ì›ì…ë‹ˆë‹¤."

# DEPRECATED: get_sales_amount_by_division - replaced by smart_query_processor
# Use smart_query_processor for questions like "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì˜ ë§¤ì¶œì•¡"

# DEPRECATED: get_pre_tax_profit_by_division - replaced by smart_query_processor
# Use smart_query_processor for questions like "ìŠ¤í…Œì¸ë¦¬ìŠ¤ì˜ ì„¸ì „ì´ìµ"

# DEPRECATED: get_sales_volume_by_supplier - replaced by smart_query_processor
# Use smart_query_processor for questions like "POSCO ê³µê¸‰ì‚¬ì˜ ë§¤ì¶œìˆ˜ëŸ‰"

# DEPRECATED: get_sales_volume_by_country - replaced by smart_query_processor
# Use smart_query_processor for questions like "í•œêµ­ì˜ ë§¤ì¶œìˆ˜ëŸ‰"

@tool
def get_overall_summary() -> str:
    """ì „ì²´ ë°ì´í„°ì…‹ì˜ ì´ ë§¤ì¶œìˆ˜ëŸ‰, ë§¤ì¶œì•¡, ì˜ì—…ì´ìµì„ ìš”ì•½í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    df = get_dataframe()
    volume = df["ë§¤ì¶œìˆ˜ëŸ‰(M/T)"].sum()
    sales = df["1.ë§¤ì¶œì•¡"].sum()
    profit = df["5.ì˜ì—…ì´ìµ"].sum()
    return f"ì´ ë§¤ì¶œìˆ˜ëŸ‰: {volume:,.0f} í†¤, ì´ ë§¤ì¶œì•¡: {sales:,.0f}ì›, ì´ ì˜ì—…ì´ìµ: {profit:,.0f}ì›ì…ë‹ˆë‹¤."

# === Phase 1: Advanced Multi-Column Tools ===

@tool
def smart_query_processor(question: str) -> str:
    """ë³µí•© ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ íŒŒì‹±í•˜ê³  advanced_multi_column_queryë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    # 1. ì—”í‹°í‹° ì¶”ì¶œ
    entities = _extract_complex_entities(question)
    
    # 2. ì¶”ì¶œëœ ì •ë³´ë¡œ advanced_multi_column_query í˜¸ì¶œ
    result = _advanced_multi_column_query(
        division=entities.get('division'),
        country=entities.get('country'),
        year=entities.get('year'),
        period=entities.get('period'),
        supplier=entities.get('supplier'),
        funds_center=entities.get('funds_center'),
        metric=entities.get('metric', 'ë§¤ì¶œìˆ˜ëŸ‰(M/T)')
    )
    
    # 3. ì¶”ì¶œ ì •ë³´ í¬í•¨í•˜ì—¬ ê²°ê³¼ ë°˜í™˜
    extraction_info = f"ğŸ“‹ ì¶”ì¶œëœ ì •ë³´:\n"
    for key, value in entities.items():
        if value:
            extraction_info += f"â€¢ {key}: {value}\n"
    
    return f"{extraction_info}\n{result}"

def _advanced_multi_column_query(
    division: str = None,
    country: str = None, 
    year: str = None,
    period: str = None,
    supplier: str = None,
    funds_center: str = None,
    metric: str = "ë§¤ì¶œìˆ˜ëŸ‰(M/T)"
) -> str:
    """ë³µí•© ì¡°ê±´ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  ì§€ì •ëœ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        division: ì‚¬ì—…ë¶€/ì‚¬ì—…ì‹¤ (ì˜ˆ: "ìŠ¤í…Œì¸ë¦¬ìŠ¤", "ì „ê¸°ê°•íŒ")
        country: êµ­ê°€ (ì˜ˆ: "í•œêµ­", "ì¤‘êµ­", "ì¼ë³¸")
        year: ì—°ë„ (ì˜ˆ: "2023", "2024") 
        period: ê¸°ê°„ (ì˜ˆ: "2022ë…„", "ìƒë°˜ê¸°", "í•˜ë°˜ê¸°", "1ë¶„ê¸°")
        supplier: ê³µê¸‰ì‚¬ (ì˜ˆ: "POSCO")
        funds_center: ê·¸ë£¹ (ì˜ˆ: "ì—´ì—°ìˆ˜ì¶œ1ê·¸ë£¹", "ëƒ‰ì—°ë‚´ìˆ˜2ê·¸ë£¹")
        metric: ì¸¡ì •í•  ì§€í‘œ (ì˜ˆ: "ë§¤ì¶œìˆ˜ëŸ‰(M/T)", "1.ë§¤ì¶œì•¡", "5.ì˜ì—…ì´ìµ")
    """
    df = get_dataframe()
    original_count = len(df)
    filters_applied = []
    
    # ì¡°ê±´ë³„ í•„í„°ë§
    if division:
        df = df[df["Division"].str.contains(division, na=False, case=False)]
        filters_applied.append(f"ì‚¬ì—…ë¶€: {division}")
    
    if country:
        df = df[df["Country"].str.contains(country, na=False, case=False)]
        filters_applied.append(f"êµ­ê°€: {country}")
    
    if year:
        # ê°•í™”ëœ ì—°ë„ ë§¤ì¹­ - íŒŒì‹± ê¸°ëŠ¥ ì‚¬ìš©
        year_matched_rows = []
        for idx, row in df.iterrows():
            parsed_info = _parse_period_year(row['Period/Year'])
            if 'year' in parsed_info and str(parsed_info['year']) == str(year):
                year_matched_rows.append(idx)
        
        if year_matched_rows:
            df = df.loc[year_matched_rows]
            filters_applied.append(f"ì—°ë„: {year} (ìŠ¤ë§ˆíŠ¸ë§¤ì¹­, {len(year_matched_rows)}ê°œ ë ˆì½”ë“œ)")
        else:
            # Fallback: ê¸°ì¡´ íŒ¨í„´ ë§¤ì¹­
            df = df[df["Period/Year"].astype(str).str.contains(str(year), na=False)]
            filters_applied.append(f"ì—°ë„: {year} (íŒ¨í„´ë§¤ì¹­)")
    
    if period:
        # ê°•í™”ëœ Period ë§¤ì¹­ - ìƒˆë¡œìš´ íŒŒì‹± ê¸°ëŠ¥ ì‚¬ìš©
        if 'Period/Year' in df.columns:
            # ì—°ë„ ì»¨í…ìŠ¤íŠ¸ ì¶”ë¡ 
            period_with_year = _infer_year_context(period)
            unique_periods = df['Period/Year'].dropna().astype(str).unique().tolist()
            
            # ë¨¼ì € ì§ì ‘ ë§¤ì¹­ ì‹œë„
            best_match, confidence = _find_best_match(period_with_year, unique_periods)
            
            if best_match and confidence >= 0.8:
                df = df[df["Period/Year"].astype(str) == best_match]
                match_info = f"ì—°ë„ì¶”ë¡ " if period != period_with_year else "ì§ì ‘ë§¤ì¹­"
                filters_applied.append(f"ê¸°ê°„: {period} â†’ {best_match} (ì‹ ë¢°ë„: {confidence:.2f}, {match_info})")
            else:
                # ìƒˆë¡œìš´ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­: íŒŒì‹±ëœ ì •ë³´ë¡œ í•„í„°ë§
                matched_rows = []
                for idx, row in df.iterrows():
                    parsed_info = _parse_period_year(row['Period/Year'])
                    
                    # AND ì¡°ê±´: ì—°ë„ì™€ ê¸°ê°„ ë‘˜ ë‹¤ ë§Œì¡±í•´ì•¼ í•¨
                    year_match = True
                    period_match = True
                    
                    # ì—°ë„ ì¡°ê±´ ê²€ì‚¬
                    if year:
                        if 'year' not in parsed_info or str(year) != str(parsed_info['year']):
                            year_match = False
                    
                    # ê¸°ê°„ ì¡°ê±´ ê²€ì‚¬
                    if "ìƒë°˜ê¸°" in period:
                        if parsed_info.get('half_year') != 'ìƒë°˜ê¸°':
                            period_match = False
                    elif "í•˜ë°˜ê¸°" in period:
                        if parsed_info.get('half_year') != 'í•˜ë°˜ê¸°':
                            period_match = False
                    elif re.search(r'(\d)ë¶„ê¸°', period):
                        quarter_match = re.search(r'(\d)ë¶„ê¸°', period)
                        if quarter_match and parsed_info.get('quarter') != f"{quarter_match.group(1)}ë¶„ê¸°":
                            period_match = False
                    # ì›” ë²”ìœ„ ì¡°ê±´ ì²˜ë¦¬
                    elif re.search(r'(\d+)ì›”ë¶€í„°\s*(\d+)ì›”|(\d+)ì›”-(\d+)ì›”', period):
                        # ì›” ë²”ìœ„ ì¶”ì¶œ
                        range_match = re.search(r'(\d+)ì›”ë¶€í„°\s*(\d+)ì›”', period) or re.search(r'(\d+)ì›”-(\d+)ì›”', period)
                        if range_match:
                            start_month = int(range_match.group(1))
                            end_month = int(range_match.group(2))
                            # ë°ì´í„°ì˜ ì›”ì´ ë²”ìœ„ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                            data_month = parsed_info.get('month_number')
                            if data_month is None or not (start_month <= data_month <= end_month):
                                period_match = False
                    
                    # ë‘˜ ë‹¤ ë§Œì¡±í•˜ëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                    if year_match and period_match:
                        matched_rows.append(idx)
                
                if matched_rows:
                    df = df.loc[matched_rows]
                    filters_applied.append(f"ê¸°ê°„: {period} (ìŠ¤ë§ˆíŠ¸ë§¤ì¹­, {len(matched_rows)}ê°œ ë ˆì½”ë“œ)")
                else:
                    # Fallback: ê¸°ì¡´ íŒ¨í„´ ë§¤ì¹­
                    print(f"ìŠ¤ë§ˆíŠ¸ë§¤ì¹­ ì‹¤íŒ¨, Fallback ì‚¬ìš©. ê¸°ê°„: {period}")
                    if "ìƒë°˜ê¸°" in period:
                        df = df[df["Period/Year"].astype(str).str.contains("ìƒë°˜ê¸°|1ë¶„ê¸°|2ë¶„ê¸°|January|February|March|April|May|June", na=False)]
                        filters_applied.append(f"ê¸°ê°„: {period} (Fallback-ìƒë°˜ê¸°, {len(df)}ê°œ ë ˆì½”ë“œ)")
                    elif "í•˜ë°˜ê¸°" in period:
                        df = df[df["Period/Year"].astype(str).str.contains("í•˜ë°˜ê¸°|3ë¶„ê¸°|4ë¶„ê¸°|July|August|September|October|November|December", na=False)]
                        filters_applied.append(f"ê¸°ê°„: {period} (Fallback-í•˜ë°˜ê¸°, {len(df)}ê°œ ë ˆì½”ë“œ)")
                    elif re.search(r'(\d+)ì›”ë¶€í„°\s*(\d+)ì›”|(\d+)ì›”-(\d+)ì›”', period):
                        # ì›” ë²”ìœ„ Fallback
                        range_match = re.search(r'(\d+)ì›”ë¶€í„°\s*(\d+)ì›”', period) or re.search(r'(\d+)ì›”-(\d+)ì›”', period)
                        if range_match:
                            start_month = int(range_match.group(1))
                            end_month = int(range_match.group(2))
                            # ì˜ì–´ ì›”ëª…ê³¼ í•œê¸€ ì›”ëª… ëª¨ë‘ ì§€ì›
                            month_names = ['January', 'February', 'March', 'April', 'May', 'June',
                                          'July', 'August', 'September', 'October', 'November', 'December']
                            target_months = month_names[start_month-1:end_month]
                            korean_months = [f"{i}ì›”" for i in range(start_month, end_month+1)]
                            pattern = '|'.join(target_months + korean_months)
                            df = df[df["Period/Year"].astype(str).str.contains(pattern, na=False)]
                            filters_applied.append(f"ê¸°ê°„: {period} (Fallback-ì›”ë²”ìœ„, {len(df)}ê°œ ë ˆì½”ë“œ)")
                    else:
                        df = df[df["Period/Year"].astype(str).str.contains(period, na=False)]
                        available_periods = ", ".join(unique_periods[:3])
                        filters_applied.append(f"ê¸°ê°„: {period} (íŒ¨í„´ë§¤ì¹­, ì‚¬ìš©ê°€ëŠ¥: {available_periods}...)")
        else:
            filters_applied.append(f"ê¸°ê°„: {period} (Period/Year ì»¬ëŸ¼ ì—†ìŒ)")
    
    if supplier:
        df = df[df["Supplier"].str.contains(supplier, na=False, case=False)]
        filters_applied.append(f"ê³µê¸‰ì‚¬: {supplier}")
    
    if funds_center:
        # ê°•í™”ëœ FundsCenter ë§¤ì¹­
        if 'FundsCenter' in df.columns:
            unique_funds = df['FundsCenter'].dropna().unique().tolist()
            best_match, confidence = _find_best_match(funds_center, unique_funds)
            
            if best_match and confidence >= 0.7:
                df = df[df["FundsCenter"] == best_match]
                match_type = "ì •í™•ë§¤ì¹­" if confidence == 1.0 else "ìœ ì‚¬ë§¤ì¹­"
                filters_applied.append(f"í€ë“œì„¼í„°: {funds_center} â†’ {best_match} (ì‹ ë¢°ë„: {confidence:.2f}, {match_type})")
            else:
                # ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ ì œì•ˆ
                df = df[df["FundsCenter"].str.contains(funds_center, na=False, case=False)]
                available_options = ", ".join(unique_funds[:5])
                filters_applied.append(f"í€ë“œì„¼í„°: {funds_center} (ë§¤ì¹­ì‹¤íŒ¨, ì‚¬ìš©ê°€ëŠ¥: {available_options}...)")
        else:
            filters_applied.append(f"í€ë“œì„¼í„°: {funds_center} (FundsCenter ì»¬ëŸ¼ ì—†ìŒ)")
    
    # ê²°ê³¼ ê³„ì‚°
    if len(df) == 0:
        return f"ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì ìš©ëœ í•„í„°: {', '.join(filters_applied)}"
    
    if metric in df.columns:
        total = df[metric].sum()
        filtered_count = len(df)
        
        # ë‹¨ìœ„ ì²˜ë¦¬ ë° ê°’ ë³€í™˜
        if metric == "ë§¤ì¶œìˆ˜ëŸ‰(M/T)":
            unit = "í†¤"
            display_value = f"{total:,.0f}{unit}"
        elif "ë§¤ì¶œì•¡" in metric or "ì´ìµ" in metric:
            # ì› ë‹¨ìœ„ ë°ì´í„°ë¥¼ ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜
            billion_value = total / 100000000  # 1ì–µ = 100,000,000
            if billion_value >= 1:
                display_value = f"{billion_value:,.0f}ì–µì›"
            else:
                display_value = f"{total:,.0f}ì›"
        else:
            display_value = f"{total:,.0f}"
        
        result = f"{', '.join(filters_applied)} ì¡°ê±´ì˜ {metric}: {display_value}"
        result += f"\n(ì´ {filtered_count:,}ê°œ ë ˆì½”ë“œ ì¤‘ì—ì„œ ì§‘ê³„, ì „ì²´ ë°ì´í„°ì˜ {filtered_count/original_count:.1%})"
        
        return result
    else:
        return f"ì§€í‘œ '{metric}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì§€í‘œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

# DEPRECATED: advanced_multi_column_query ì œê±°ë¨
# smart_query_processor ì‚¬ìš© ê¶Œì¥

@tool
def comparative_analysis_tool(
    condition1_division: str = None,
    condition1_country: str = None,
    condition1_year: str = None,
    condition2_division: str = None, 
    condition2_country: str = None,
    condition2_year: str = None,
    metric: str = "ë§¤ì¶œìˆ˜ëŸ‰(M/T)"
) -> str:
    """ë‘ ì¡°ê±´ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
    
    ì˜ˆì‹œ: 2023ë…„ í•œêµ­ vs 2023ë…„ ì¤‘êµ­ ë§¤ì¶œ ë¹„êµ
    ìŠ¤í…Œì¸ë¦¬ìŠ¤ vs ì „ê¸°ê°•íŒ ì˜ì—…ì´ìµ ë¹„êµ
    """
    df = get_dataframe()
    
    # ì¡°ê±´1 ë°ì´í„° í•„í„°ë§
    df1 = df.copy()
    condition1_desc = []
    if condition1_division:
        df1 = df1[df1["Division"].str.contains(condition1_division, na=False, case=False)]
        condition1_desc.append(f"{condition1_division}")
    if condition1_country:
        df1 = df1[df1["Country"].str.contains(condition1_country, na=False, case=False)]
        condition1_desc.append(f"{condition1_country}")
    if condition1_year:
        df1 = df1[df1["Period/Year"].astype(str).str.contains(str(condition1_year), na=False)]
        condition1_desc.append(f"{condition1_year}ë…„")
    
    # ì¡°ê±´2 ë°ì´í„° í•„í„°ë§
    df2 = df.copy()
    condition2_desc = []
    if condition2_division:
        df2 = df2[df2["Division"].str.contains(condition2_division, na=False, case=False)]
        condition2_desc.append(f"{condition2_division}")
    if condition2_country:
        df2 = df2[df2["Country"].str.contains(condition2_country, na=False, case=False)]
        condition2_desc.append(f"{condition2_country}")
    if condition2_year:
        df2 = df2[df2["Period/Year"].astype(str).str.contains(str(condition2_year), na=False)]
        condition2_desc.append(f"{condition2_year}ë…„")
    
    # ê²°ê³¼ ê³„ì‚°
    if metric in df.columns:
        result1 = df1[metric].sum()
        result2 = df2[metric].sum()
        
        # ì°¨ì´ ê³„ì‚°
        diff = result1 - result2
        diff_pct = (diff / result2 * 100) if result2 != 0 else 0
        
        # ë‹¨ìœ„ ì„¤ì •
        if metric == "ë§¤ì¶œìˆ˜ëŸ‰(M/T)":
            unit = "í†¤"
        elif "ë§¤ì¶œì•¡" in metric or "ì´ìµ" in metric:
            unit = "ì–µì›"
        else:
            unit = ""
        
        condition1_name = " ".join(condition1_desc) if condition1_desc else "ì¡°ê±´1"
        condition2_name = " ".join(condition2_desc) if condition2_desc else "ì¡°ê±´2"
        
        result = f"ğŸ“Š ë¹„êµ ë¶„ì„ ê²°ê³¼:\n"
        result += f"â€¢ {condition1_name}: {result1:,.0f}{unit}\n"
        result += f"â€¢ {condition2_name}: {result2:,.0f}{unit}\n"
        result += f"â€¢ ì°¨ì´: {diff:,.0f}{unit} ({diff_pct:+.1f}%)\n"
        
        if diff > 0:
            result += f"â†’ {condition1_name}ì´ {condition2_name}ë³´ë‹¤ {abs(diff):,.0f}{unit} ë§ìŠµë‹ˆë‹¤."
        else:
            result += f"â†’ {condition2_name}ì´ {condition1_name}ë³´ë‹¤ {abs(diff):,.0f}{unit} ë§ìŠµë‹ˆë‹¤."
        
        return result
    else:
        return f"ì§€í‘œ '{metric}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

import re
from datetime import datetime
from difflib import SequenceMatcher

def _normalize_korean_text(text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    if not text:
        return ""
    
    text = str(text).strip()
    
    # ìˆ«ì ìœ„ì¹˜ ì •ê·œí™”: "ê·¸ë£¹1" <-> "1ê·¸ë£¹"
    # "ì—´ì—°ìˆ˜ì¶œê·¸ë£¹1" -> "ì—´ì—°ìˆ˜ì¶œ1ê·¸ë£¹" í˜•íƒœë¡œ í†µì¼
    text = re.sub(r'([ê°€-í£]+)ê·¸ë£¹(\d+)', r'\1\2ê·¸ë£¹', text)
    
    # ê³µë°± ì œê±°
    text = re.sub(r'\s+', '', text)
    
    return text

def _find_best_match(target: str, candidates: list, min_similarity: float = 0.7) -> tuple:
    """ìµœì  ë§¤ì¹­ì„ ì°¾ìŠµë‹ˆë‹¤. (ë§¤ì¹­ê°’, ì‹ ë¢°ë„) ë°˜í™˜"""
    if not target or not candidates:
        return None, 0.0
    
    target_normalized = _normalize_korean_text(target)
    best_match = None
    best_score = 0.0
    
    for candidate in candidates:
        candidate_str = str(candidate)
        candidate_normalized = _normalize_korean_text(candidate_str)
        
        # 1. ì •í™• ë§¤ì¹­ (ì •ê·œí™” í›„)
        if target_normalized == candidate_normalized:
            return candidate_str, 1.0
        
        # 2. ë¶€ë¶„ ë§¤ì¹­ (ì–‘ë°©í–¥)
        if target_normalized in candidate_normalized or candidate_normalized in target_normalized:
            score = 0.9
            if score > best_score:
                best_match = candidate_str
                best_score = score
        
        # 3. ìœ ì‚¬ë„ ë§¤ì¹­
        similarity = SequenceMatcher(None, target_normalized, candidate_normalized).ratio()
        if similarity > best_score and similarity >= min_similarity:
            best_match = candidate_str
            best_score = similarity
        
        # 4. í‚¤ì›Œë“œ ë§¤ì¹­ (ê·¸ë£¹ëª… íŠ¹í™”)
        if 'ê·¸ë£¹' in target_normalized and 'ê·¸ë£¹' in candidate_normalized:
            # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ("ì—´ì—°ìˆ˜ì¶œ" ë“±)
            target_base = re.sub(r'\d*ê·¸ë£¹.*', '', target_normalized)
            candidate_base = re.sub(r'\d*ê·¸ë£¹.*', '', candidate_normalized)
            
            if target_base and candidate_base and target_base in candidate_base:
                score = 0.8
                if score > best_score:
                    best_match = candidate_str
                    best_score = score
    
    return best_match, best_score

def _infer_year_context(period: str) -> str:
    """ê¸°ê°„ì—ì„œ ì—°ë„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤."""
    if not period:
        return period
    
    # ì´ë¯¸ ì—°ë„ê°€ í¬í•¨ëœ ê²½ìš°
    if re.search(r'20\d{2}', period):
        return period
    
    # í˜„ì¬ ì—°ë„ ì¶”ê°€
    current_year = datetime.now().year
    
    if 'ìƒë°˜ê¸°' in period:
        return f"{current_year}ë…„ìƒë°˜ê¸°"
    elif 'í•˜ë°˜ê¸°' in period:
        return f"{current_year}ë…„í•˜ë°˜ê¸°"
    elif re.search(r'\d+ë¶„ê¸°', period):
        return f"{current_year}ë…„{period}"
    
    return period

def _parse_period_year(period_value: str) -> dict:
    """Period/Year ì»¬ëŸ¼ì˜ ë‹¤ì–‘í•œ í˜•ì‹ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    ì§€ì› í˜•ì‹:
    - '2023.001 January 2023'
    - '2023ë…„ 1ì›”'
    - '2023ë…„ ìƒë°˜ê¸°'
    - '2023 Q1'
    """
    if not period_value or pd.isna(period_value):
        return {}
    
    period_str = str(period_value).strip()
    parsed_info = {}
    
    # íŒ¨í„´ 1: "2023.001 January 2023" í˜•ì‹
    match = re.match(r'(\d{4})\.(\d{3})\s+(\w+)\s+(\d{4})', period_str)
    if match:
        year = match.group(1)
        period_code = match.group(2)
        month_name = match.group(3)
        year2 = match.group(4)
        
        parsed_info.update({
            'year': year,
            'period_code': period_code,
            'month_name': month_name,
            'month_number': _month_name_to_number(month_name),
            'quarter': _month_to_quarter(_month_name_to_number(month_name)),
            'half_year': 'ìƒë°˜ê¸°' if _month_name_to_number(month_name) <= 6 else 'í•˜ë°˜ê¸°'
        })
        return parsed_info
    
    # íŒ¨í„´ 2: "2023ë…„ 1ì›”" í˜•ì‹
    match = re.match(r'(\d{4})ë…„\s*(\d{1,2})ì›”', period_str)
    if match:
        year = match.group(1)
        month = int(match.group(2))
        
        parsed_info.update({
            'year': year,
            'month_number': month,
            'quarter': _month_to_quarter(month),
            'half_year': 'ìƒë°˜ê¸°' if month <= 6 else 'í•˜ë°˜ê¸°'
        })
        return parsed_info
    
    # íŒ¨í„´ 3: "2023ë…„ ìƒë°˜ê¸°/í•˜ë°˜ê¸°" í˜•ì‹
    match = re.match(r'(\d{4})ë…„\s*(ìƒë°˜ê¸°|í•˜ë°˜ê¸°)', period_str)
    if match:
        year = match.group(1)
        half = match.group(2)
        
        parsed_info.update({
            'year': year,
            'half_year': half
        })
        return parsed_info
    
    # íŒ¨í„´ 4: ì—°ë„ë§Œ ì¶”ì¶œ
    year_match = re.search(r'(\d{4})', period_str)
    if year_match:
        parsed_info['year'] = year_match.group(1)
    
    return parsed_info

def _month_name_to_number(month_name: str) -> int:
    """ì˜ë¬¸ ì›”ëª…ì„ ìˆ«ìë¡œ ë³€í™˜"""
    month_mapping = {
        'January': 1, 'February': 2, 'March': 3, 'April': 4,
        'May': 5, 'June': 6, 'July': 7, 'August': 8,
        'September': 9, 'October': 10, 'November': 11, 'December': 12
    }
    return month_mapping.get(month_name, 0)

def _month_to_quarter(month: int) -> str:
    """ì›”ì„ ë¶„ê¸°ë¡œ ë³€í™˜"""
    if month in [1, 2, 3]:
        return '1ë¶„ê¸°'
    elif month in [4, 5, 6]:
        return '2ë¶„ê¸°'
    elif month in [7, 8, 9]:
        return '3ë¶„ê¸°'
    elif month in [10, 11, 12]:
        return '4ë¶„ê¸°'
    return ''

def _extract_complex_entities(question: str) -> dict:
    """ë³µí•© ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹°ë¥¼ ì •êµí•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    entities = {
        'funds_center': None,
        'division': None,
        'country': None,
        'period': None,
        'year': None,
        'supplier': None,
        'metric': None
    }
    
    # ê·¸ë£¹ëª… íŒ¨í„´ (ìˆ«ì í¬í•¨)
    group_patterns = [
        r'([ê°€-í£]+(?:ìˆ˜ì¶œ|ë‚´ìˆ˜)?\d*ê·¸ë£¹)',  # ì—´ì—°ìˆ˜ì¶œ1ê·¸ë£¹, ëƒ‰ì—°ë‚´ìˆ˜2ê·¸ë£¹
        r'([ê°€-í£]+\d+ê·¸ë£¹)',              # ìŠ¤í…Œì¸ë¦¬ìŠ¤1ê·¸ë£¹
        r'(\w+ê·¸ë£¹\d*)',                    # ì˜ë¬¸ê·¸ë£¹
    ]
    
    for pattern in group_patterns:
        match = re.search(pattern, question)
        if match:
            entities['funds_center'] = match.group(1)
            break
    
    # ì‚¬ì—…ë¶€/Division íŒ¨í„´
    division_patterns = ['ìŠ¤í…Œì¸ë¦¬ìŠ¤', 'ëª¨ë¹Œë¦¬í‹°', 'ì—´ì—°ì¡°ê°•', 'ëƒ‰ì—°', 'í›„íŒì„ ì¬', 'ìŠ¤í…Œì¸ë ˆìŠ¤', 'ì—ë„ˆì§€ì¸í”„ë¼ê°•ì¬', 'ìë™ì°¨ì†Œì¬']
    for div in division_patterns:
        if div in question:
            entities['division'] = div
            break
    
    # ê¸°ê°„ íŒ¨í„´ - ì›” ë²”ìœ„ ì¡°ê±´ ì¶”ê°€
    if 'ìƒë°˜ê¸°' in question:
        entities['period'] = 'ìƒë°˜ê¸°'
    elif 'í•˜ë°˜ê¸°' in question:
        entities['period'] = 'í•˜ë°˜ê¸°'
    elif re.search(r'(\d+)ë¶„ê¸°', question):
        quarter_match = re.search(r'(\d+)ë¶„ê¸°', question)
        entities['period'] = f"{quarter_match.group(1)}ë¶„ê¸°"
    # ì›” ë²”ìœ„ íŒ¨í„´: "7ì›”ë¶€í„° 12ì›”", "1ì›”-6ì›”" ë“±
    elif re.search(r'(\d+)ì›”ë¶€í„°\s*(\d+)ì›”', question):
        month_range_match = re.search(r'(\d+)ì›”ë¶€í„°\s*(\d+)ì›”', question)
        start_month = int(month_range_match.group(1))
        end_month = int(month_range_match.group(2))
        entities['period'] = f"{start_month}ì›”ë¶€í„°{end_month}ì›”"
        entities['month_range'] = (start_month, end_month)
    elif re.search(r'(\d+)ì›”-(\d+)ì›”', question):
        month_range_match = re.search(r'(\d+)ì›”-(\d+)ì›”', question)
        start_month = int(month_range_match.group(1))
        end_month = int(month_range_match.group(2))
        entities['period'] = f"{start_month}ì›”-{end_month}ì›”"
        entities['month_range'] = (start_month, end_month)
    
    # ì—°ë„ íŒ¨í„´
    year_match = re.search(r'(20\d{2})', question)
    if year_match:
        entities['year'] = year_match.group(1)
    
    
    # êµ­ê°€ íŒ¨í„´
    countries = ['í•œêµ­', 'ì¤‘êµ­', 'ì¼ë³¸', 'ë¯¸êµ­', 'ë…ì¼', 'ì¸ë„', 'ë² íŠ¸ë‚¨', 'íƒœêµ­' ]
    for country in countries:
        if country in question:
            entities['country'] = country
            break
    
    # ë©”íŠ¸ë¦­ íŒ¨í„´
    if 'ì˜ì—…ì´ìµ' in question:
        entities['metric'] = '5.ì˜ì—…ì´ìµ'
    elif 'ë§¤ì¶œì•¡' in question:
        entities['metric'] = '1.ë§¤ì¶œì•¡'
    elif 'ì„¸ì „ì´ìµ' in question:
        entities['metric'] = '8.ì„¸ì „ì´ìµ'
    elif 'ë§¤ì¶œìˆ˜ëŸ‰' in question or 'íŒë§¤ëŸ‰' in question or 'ìˆ˜ëŸ‰' in question:
        entities['metric'] = 'ë§¤ì¶œìˆ˜ëŸ‰(M/T)'
    else:
        entities['metric'] = 'ë§¤ì¶œìˆ˜ëŸ‰(M/T)'  # ê¸°ë³¸ê°’
    
    return entities

# extract_complex_entities removed - now integrated into smart_query_processor

# detect_relevant_columns simplified - most functionality now in smart_query_processor
# Keeping only basic column detection for backward compatibility

# === Phase 1.2: Data Exploration Tools ===

@tool
def get_unique_values(column_name: str, limit: int = 50) -> str:
    """ì§€ì •ëœ ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    df = get_dataframe()
    
    if column_name not in df.columns:
        available_columns = ", ".join(df.columns[:10])
        return f"âŒ '{column_name}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_columns}..."
    
    unique_values = df[column_name].dropna().unique()
    total_count = len(unique_values)
    
    # ê²°ê³¼ ì •ë ¬ (ê°€ëŠ¥í•œ ê²½ìš°)
    try:
        unique_values = sorted(unique_values)
    except:
        pass  # ì •ë ¬ ë¶ˆê°€ëŠ¥í•œ íƒ€ì…ì¸ ê²½ìš° ì›ë³¸ ìˆœì„œ ìœ ì§€
    
    # limit ì ìš©
    display_values = unique_values[:limit]
    
    result = f"ğŸ“‹ {column_name} ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ëª©ë¡:\n"
    result += f"ğŸ“Š ì´ {total_count}ê°œì˜ ê³ ìœ ê°’\n\n"
    
    for i, value in enumerate(display_values, 1):
        result += f"{i:2d}. {value}\n"
    
    if total_count > limit:
        result += f"\n... ë° {total_count - limit}ê°œ ì¶”ê°€ ê°’"
    
    return result

@tool
def get_column_info(column_name: str) -> str:
    """ì§€ì •ëœ ì»¬ëŸ¼ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    df = get_dataframe()
    
    if column_name not in df.columns:
        available_columns = ", ".join(df.columns[:10])
        return f"âŒ '{column_name}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_columns}..."
    
    column_data = df[column_name]
    
    result = f"ğŸ“Š {column_name} ì»¬ëŸ¼ ì •ë³´:\n"
    result += f"â€¢ ë°ì´í„° íƒ€ì…: {column_data.dtype}\n"
    result += f"â€¢ ì´ í–‰ ìˆ˜: {len(column_data):,}\n"
    result += f"â€¢ ê²°ì¸¡ê°’: {column_data.isnull().sum():,}ê°œ\n"
    result += f"â€¢ ê³ ìœ ê°’ ìˆ˜: {column_data.nunique():,}ê°œ\n"
    
    # ë°ì´í„° íƒ€ì…ë³„ ìƒì„¸ ì •ë³´
    if column_data.dtype in ['object', 'string']:
        result += f"\nğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìƒì„¸:\n"
        
        # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ìƒìœ„ 10ê°œ ê°’
        top_values = column_data.value_counts().head(10)
        result += f"â€¢ ìµœë¹ˆê°’ TOP 10:\n"
        for idx, (value, count) in enumerate(top_values.items(), 1):
            percentage = (count / len(column_data)) * 100
            result += f"  {idx:2d}. {value} ({count:,}ê°œ, {percentage:.1f}%)\n"
            
    elif column_data.dtype in ['int64', 'float64']:
        result += f"\nğŸ“ˆ ìˆ«ì ì»¬ëŸ¼ ìƒì„¸:\n"
        result += f"â€¢ ìµœì†Ÿê°’: {column_data.min():,.0f}\n"
        result += f"â€¢ ìµœëŒ“ê°’: {column_data.max():,.0f}\n"
        result += f"â€¢ í‰ê· ê°’: {column_data.mean():,.0f}\n"
        result += f"â€¢ ì¤‘ì•™ê°’: {column_data.median():,.0f}\n"
    
    return result

@tool
def explore_dataset() -> str:
    """ë°ì´í„°ì…‹ì˜ ì „ì²´ êµ¬ì¡°ì™€ ê¸°ë³¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
    df = get_dataframe()
    
    result = f"ğŸ“Š ë°ì´í„°ì…‹ ì „ì²´ ê°œìš”:\n"
    result += f"â€¢ ì´ í–‰ ìˆ˜: {len(df):,}\n"
    result += f"â€¢ ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}\n"
    result += f"â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\n\n"
    
    result += f"ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡ ë° ê¸°ë³¸ ì •ë³´:\n"
    for i, col in enumerate(df.columns, 1):
        dtype = str(df[col].dtype)
        null_count = df[col].isnull().sum()
        unique_count = df[col].nunique()
        
        result += f"{i:2d}. {col}\n"
        result += f"    - íƒ€ì…: {dtype}\n"
        result += f"    - ê³ ìœ ê°’: {unique_count:,}ê°œ\n"
        result += f"    - ê²°ì¸¡ê°’: {null_count:,}ê°œ\n"
        
        # ìƒ˜í”Œ ê°’ í‘œì‹œ (í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì˜ ê²½ìš°)
        if dtype == 'object' and unique_count <= 20:
            sample_values = df[col].dropna().unique()[:5]
            sample_str = ", ".join([str(v) for v in sample_values])
            if len(sample_str) > 50:
                sample_str = sample_str[:47] + "..."
            result += f"    - ìƒ˜í”Œ: {sample_str}\n"
        result += "\n"
    
    return result

@tool
def test_period_recognition(sample_limit: int = 10) -> str:
    """Period/Year ì»¬ëŸ¼ì˜ ì¸ì‹ ëŠ¥ë ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    df = get_dataframe()
    
    if 'Period/Year' not in df.columns:
        return "âŒ Period/Year ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"ğŸ§ª Period/Year ì¸ì‹ í…ŒìŠ¤íŠ¸:\n\n"
    
    # ìƒ˜í”Œ ë°ì´í„° ë¶„ì„
    sample_periods = df['Period/Year'].dropna().unique()[:sample_limit]
    
    for period_value in sample_periods:
        parsed = _parse_period_year(period_value)
        
        result += f"ì›ë³¸: '{period_value}'\n"
        if parsed:
            result += f"  âœ… íŒŒì‹± ì„±ê³µ:\n"
            for key, value in parsed.items():
                result += f"     â€¢ {key}: {value}\n"
        else:
            result += f"  âŒ íŒŒì‹± ì‹¤íŒ¨\n"
        result += "\n"
    
    return result
import pandas as pd
from langchain_core.tools import tool

# ì „ì—­ ë³€ìˆ˜ë¡œ ì—¬ëŸ¬ ë°ì´í„°ì…‹ ê´€ë¦¬
_global_datasets = {}

def set_datasets(datasets_dict: dict):
    """ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    global _global_datasets
    _global_datasets = datasets_dict

def get_datasets() -> dict:
    """ëª¨ë“  ë°ì´í„°ì…‹ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _global_datasets
    return _global_datasets

@tool
def compare_datasets_summary() -> str:
    """ì—…ë¡œë“œëœ ëª¨ë“  ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""
    datasets = get_datasets()
    
    if len(datasets) < 2:
        return "âŒ ë¹„êµí•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë°ì´í„°ì…‹ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    result = "ğŸ“Š ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´ ë¹„êµ:\n\n"
    
    for name, df in datasets.items():
        result += f"ğŸ—‚ï¸ **{name}**\n"
        result += f"  â€¢ í–‰ ìˆ˜: {len(df):,}ê°œ\n"
        result += f"  â€¢ ì—´ ìˆ˜: {len(df.columns)}ê°œ\n"
        result += f"  â€¢ ë©”ëª¨ë¦¬: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB\n"
        result += f"  â€¢ ê²°ì¸¡ê°’: {df.isnull().sum().sum():,}ê°œ\n"
        
        # ì£¼ìš” ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìš”ì•½
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            result += f"  â€¢ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {len(numeric_cols)}ê°œ\n"
        result += "\n"
    
    return result

@tool  
def compare_datasets_metrics(metric: str = "ë§¤ì¶œìˆ˜ëŸ‰(M/T)") -> str:
    """ì—¬ëŸ¬ ë°ì´í„°ì…‹ ê°„ì˜ íŠ¹ì • ì§€í‘œë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""
    datasets = get_datasets()
    
    if len(datasets) < 2:
        return "âŒ ë¹„êµí•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë°ì´í„°ì…‹ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    result = f"ğŸ“ˆ {metric} ë¹„êµ ë¶„ì„:\n\n"
    metric_results = {}
    
    for name, df in datasets.items():
        if metric in df.columns:
            total = df[metric].sum()
            mean = df[metric].mean()
            count = len(df[df[metric].notna()])
            
            metric_results[name] = {
                'total': total,
                'mean': mean, 
                'count': count
            }
            
            # ë‹¨ìœ„ ì²˜ë¦¬
            if metric == "ë§¤ì¶œìˆ˜ëŸ‰(M/T)":
                unit = "í†¤"
            elif "ë§¤ì¶œì•¡" in metric or "ì´ìµ" in metric:
                unit = "ì–µì›"
            else:
                unit = ""
            
            result += f"ğŸ—‚ï¸ **{name}**\n"
            result += f"  â€¢ ì´í•©: {total:,.0f}{unit}\n"
            result += f"  â€¢ í‰ê· : {mean:,.0f}{unit}\n"
            result += f"  â€¢ ë ˆì½”ë“œ ìˆ˜: {count:,}ê°œ\n\n"
        else:
            result += f"ğŸ—‚ï¸ **{name}**: âŒ '{metric}' ì»¬ëŸ¼ ì—†ìŒ\n\n"
    
    # ìˆœìœ„ ë° ì°¨ì´ ë¶„ì„
    if len(metric_results) >= 2:
        sorted_results = sorted(metric_results.items(), key=lambda x: x[1]['total'], reverse=True)
        
        result += "ğŸ† **ìˆœìœ„ ë° ì°¨ì´ ë¶„ì„:**\n"
        for i, (name, data) in enumerate(sorted_results, 1):
            unit = "í†¤" if metric == "ë§¤ì¶œìˆ˜ëŸ‰(M/T)" else "ì–µì›" if "ë§¤ì¶œì•¡" in metric or "ì´ìµ" in metric else ""
            result += f"  {i}. {name}: {data['total']:,.0f}{unit}\n"
        
        if len(sorted_results) >= 2:
            top_name, top_data = sorted_results[0]
            second_name, second_data = sorted_results[1]
            diff = top_data['total'] - second_data['total']
            diff_pct = (diff / second_data['total'] * 100) if second_data['total'] != 0 else 0
            
            result += f"\nğŸ“Š **{top_name}**ì´ **{second_name}**ë³´ë‹¤ {diff:,.0f}{unit} ë§ìŒ (+{diff_pct:.1f}%)\n"
    
    return result

@tool
def compare_datasets_by_division(division: str = None) -> str:
    """ì—¬ëŸ¬ ë°ì´í„°ì…‹ì—ì„œ íŠ¹ì • ì‚¬ì—…ë¶€ë³„ ë°ì´í„°ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."""
    datasets = get_datasets()
    
    if len(datasets) < 2:
        return "âŒ ë¹„êµí•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë°ì´í„°ì…‹ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    result = f"ğŸ¢ ì‚¬ì—…ë¶€ë³„ ë¹„êµ ë¶„ì„"
    if division:
        result += f" - {division}"
    result += ":\n\n"
    
    for name, df in datasets.items():
        filtered_df = df
        
        if division and 'Division' in df.columns:
            filtered_df = df[df["Division"].str.contains(division, na=False, case=False)]
        
        result += f"ğŸ—‚ï¸ **{name}**\n"
        
        if 'Division' in df.columns:
            if division:
                result += f"  ğŸ“‹ {division} ê´€ë ¨ ë°ì´í„°:\n"
            else:
                result += f"  ğŸ“‹ ì „ì²´ ì‚¬ì—…ë¶€ í˜„í™©:\n"
            
            # ë§¤ì¶œìˆ˜ëŸ‰ ì§‘ê³„
            if "ë§¤ì¶œìˆ˜ëŸ‰(M/T)" in filtered_df.columns:
                volume = filtered_df["ë§¤ì¶œìˆ˜ëŸ‰(M/T)"].sum()
                result += f"    â€¢ ë§¤ì¶œìˆ˜ëŸ‰: {volume:,.0f} í†¤\n"
            
            # ë§¤ì¶œì•¡ ì§‘ê³„  
            if "1.ë§¤ì¶œì•¡" in filtered_df.columns:
                sales = filtered_df["1.ë§¤ì¶œì•¡"].sum()
                result += f"    â€¢ ë§¤ì¶œì•¡: {sales:,.0f} ì–µì›\n"
            
            # ì˜ì—…ì´ìµ ì§‘ê³„
            if "5.ì˜ì—…ì´ìµ" in filtered_df.columns:
                profit = filtered_df["5.ì˜ì—…ì´ìµ"].sum()
                result += f"    â€¢ ì˜ì—…ì´ìµ: {profit:,.0f} ì–µì›\n"
            
            result += f"    â€¢ ë ˆì½”ë“œ ìˆ˜: {len(filtered_df):,}ê°œ\n"
            
            # ì‚¬ì—…ë¶€ë³„ ìƒì„¸ (ì „ì²´ ì¡°íšŒì‹œ)
            if not division and "ë§¤ì¶œìˆ˜ëŸ‰(M/T)" in filtered_df.columns:
                division_summary = filtered_df.groupby('Division')['ë§¤ì¶œìˆ˜ëŸ‰(M/T)'].sum().reset_index()
                division_summary = division_summary.sort_values('ë§¤ì¶œìˆ˜ëŸ‰(M/T)', ascending=False)
                
                if len(division_summary) > 0:
                    result += f"    ğŸ“Š ìƒìœ„ 3ê°œ ì‚¬ì—…ë¶€:\n"
                    for idx, row in division_summary.head(3).iterrows():
                        result += f"      {idx+1}. {row['Division']}: {row['ë§¤ì¶œìˆ˜ëŸ‰(M/T)']:,.0f} í†¤\n"
        else:
            result += f"  âŒ Division ì»¬ëŸ¼ ì—†ìŒ\n"
        
        result += "\n"
    
    return result

@tool
def integrated_dataset_analysis(metric: str = "ë§¤ì¶œìˆ˜ëŸ‰(M/T)", group_by: str = "Division") -> str:
    """ëª¨ë“  ë°ì´í„°ì…‹ì„ í†µí•©í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤."""
    datasets = get_datasets()
    
    if len(datasets) < 2:
        return "âŒ í†µí•© ë¶„ì„í•˜ë ¤ë©´ ìµœì†Œ 2ê°œì˜ ë°ì´í„°ì…‹ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    # ëª¨ë“  ë°ì´í„°ì…‹ í†µí•©
    combined_data = []
    for name, df in datasets.items():
        df_copy = df.copy()
        df_copy['ë°ì´í„°ì…‹'] = name
        combined_data.append(df_copy)
    
    integrated_df = pd.concat(combined_data, ignore_index=True)
    
    result = f"ğŸ“Š í†µí•© ë°ì´í„°ì…‹ ë¶„ì„ ({metric} ê¸°ì¤€):\n\n"
    result += f"ğŸ”— **í†µí•© ì •ë³´:**\n"
    result += f"  â€¢ ì´ í–‰ ìˆ˜: {len(integrated_df):,}ê°œ\n"
    result += f"  â€¢ ë°ì´í„°ì…‹ ìˆ˜: {len(datasets)}ê°œ\n"
    result += f"  â€¢ í†µí•© í›„ ë©”ëª¨ë¦¬: {integrated_df.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB\n\n"
    
    if metric in integrated_df.columns and group_by in integrated_df.columns:
        # ê·¸ë£¹ë³„ í†µí•© ë¶„ì„
        grouped = integrated_df.groupby(group_by)[metric].agg(['sum', 'mean', 'count']).reset_index()
        grouped = grouped.sort_values('sum', ascending=False)
        
        result += f"ğŸ“ˆ **{group_by}ë³„ {metric} í†µí•© ìˆœìœ„:**\n"
        
        # ë‹¨ìœ„ ì²˜ë¦¬
        if metric == "ë§¤ì¶œìˆ˜ëŸ‰(M/T)":
            unit = "í†¤"
        elif "ë§¤ì¶œì•¡" in metric or "ì´ìµ" in metric:
            unit = "ì–µì›"
        else:
            unit = ""
        
        for idx, row in grouped.head(10).iterrows():
            result += f"  {idx+1}. {row[group_by]}: {row['sum']:,.0f}{unit} (í‰ê· : {row['mean']:,.0f}{unit})\n"
        
        # ë°ì´í„°ì…‹ë³„ ê¸°ì—¬ë„ ë¶„ì„
        result += f"\nğŸ¯ **ë°ì´í„°ì…‹ë³„ ê¸°ì—¬ë„ ë¶„ì„:**\n"
        dataset_contribution = integrated_df.groupby('ë°ì´í„°ì…‹')[metric].sum().reset_index()
        dataset_contribution = dataset_contribution.sort_values(metric, ascending=False)
        
        total_sum = dataset_contribution[metric].sum()
        
        for idx, row in dataset_contribution.iterrows():
            contribution_pct = (row[metric] / total_sum * 100) if total_sum > 0 else 0
            result += f"  â€¢ {row['ë°ì´í„°ì…‹']}: {row[metric]:,.0f}{unit} ({contribution_pct:.1f}%)\n"
        
    else:
        result += f"âŒ '{metric}' ë˜ëŠ” '{group_by}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
    
    return result