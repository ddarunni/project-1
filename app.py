# app.py
import streamlit as st
import pandas as pd
from agent.graph_flow import graph_executor
from agent.tools import *
import sys
import os
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

# from agent import tools
# tools.df = pd.read_excel("path_to_your_file.xlsx")

import re
from dotenv import load_dotenv

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")


st.set_page_config(page_title="ğŸ“Š ì² ê°• ë°ì´í„° ë¶„ì„ Q&A", layout="wide")
st.title("ğŸ“Š ì² ê°• ì‹¤ì  ë°ì´í„° ë¶„ì„ (LangGraph ê¸°ë°˜)")

# ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ
uploaded_files = st.file_uploader(
    "ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)", 
    type=["xlsx", "csv"], 
    accept_multiple_files=True
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "uploaded_datasets" not in st.session_state:
    st.session_state.uploaded_datasets = {}
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "active_dataset" not in st.session_state:
    st.session_state.active_dataset = None

if uploaded_files:
    # ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ì²˜ë¦¬
    for uploaded_file in uploaded_files:
        file_key = f"{uploaded_file.name}_{uploaded_file.size}"
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
        if file_key not in st.session_state.uploaded_datasets:
            try:
                # ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬
                if uploaded_file.name.endswith('.xlsx'):
                    xls = pd.ExcelFile(uploaded_file)
                    sheets_data = {}
                    
                    for sheet_name in xls.sheet_names:
                        df = xls.parse(sheet_name)
                        df.columns = df.columns.str.strip().str.replace(" ", "").str.replace("\t", "")
                        sheets_data[sheet_name] = df
                    
                    st.session_state.uploaded_datasets[file_key] = {
                        'name': uploaded_file.name,
                        'sheets': sheets_data,
                        'file_type': 'excel'
                    }
                    
                # CSV íŒŒì¼ ì²˜ë¦¬  
                elif uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                    df.columns = df.columns.str.strip().str.replace(" ", "").str.replace("\t", "")
                    
                    st.session_state.uploaded_datasets[file_key] = {
                        'name': uploaded_file.name,
                        'sheets': {'Sheet1': df},
                        'file_type': 'csv'
                    }
                    
            except Exception as e:
                st.error(f"íŒŒì¼ '{uploaded_file.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
    if st.session_state.uploaded_datasets:
        st.markdown("### ğŸ“ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡")
        
        # íŒŒì¼ ì„ íƒ UI
        file_options = []
        file_keys = []
        for key, dataset in st.session_state.uploaded_datasets.items():
            for sheet_name in dataset['sheets'].keys():
                display_name = f"{dataset['name']} - {sheet_name}"
                file_options.append(display_name)
                file_keys.append((key, sheet_name))
        
        selected_idx = st.selectbox(
            "ğŸ¯ ë¶„ì„í•  ë°ì´í„°ì…‹ ì„ íƒ:", 
            range(len(file_options)),
            format_func=lambda x: file_options[x]
        )
        
        if selected_idx is not None:
            selected_key, selected_sheet = file_keys[selected_idx]
            selected_dataset = st.session_state.uploaded_datasets[selected_key]
            df = selected_dataset['sheets'][selected_sheet]
            
            # í™œì„± ë°ì´í„°ì…‹ ì €ì¥
            st.session_state.active_dataset = {
                'df': df,
                'name': f"{selected_dataset['name']} - {selected_sheet}",
                'file_key': selected_key,
                'sheet_name': selected_sheet
            }
            
            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            with st.expander(f"ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°: {selected_dataset['name']} - {selected_sheet}", expanded=True):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í–‰ ìˆ˜", f"{len(df):,}")
                with col2:
                    st.metric("ì—´ ìˆ˜", f"{len(df.columns)}")
                with col3:
                    st.metric("ë©”ëª¨ë¦¬", f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB")
                with col4:
                    st.metric("ê²°ì¸¡ê°’", f"{df.isnull().sum().sum():,}")
                
                st.dataframe(df.head(100), use_container_width=True)
        
        # íŒŒì¼ ë¹„êµ ì„¹ì…˜
        if len(st.session_state.uploaded_datasets) >= 2:
            st.markdown("### ğŸ” íŒŒì¼ ê°„ ë¹„êµ ë¶„ì„")
            
            col1, col2 = st.columns(2)
            
            with col1:
                compare_idx1 = st.selectbox(
                    "ë¹„êµ ëŒ€ìƒ 1:",
                    range(len(file_options)),
                    format_func=lambda x: file_options[x],
                    key="compare1"
                )
            
            with col2:
                compare_idx2 = st.selectbox(
                    "ë¹„êµ ëŒ€ìƒ 2:",
                    range(len(file_options)),
                    format_func=lambda x: file_options[x],
                    key="compare2"
                )
            
            if compare_idx1 != compare_idx2:
                if st.button("ğŸ“ˆ ë¹„êµ ë¶„ì„ ì‹œì‘"):
                    key1, sheet1 = file_keys[compare_idx1]
                    key2, sheet2 = file_keys[compare_idx2]
                    
                    df1 = st.session_state.uploaded_datasets[key1]['sheets'][sheet1]
                    df2 = st.session_state.uploaded_datasets[key2]['sheets'][sheet2]
                    
                    # ê¸°ë³¸ ë¹„êµ ì •ë³´
                    st.markdown("#### ğŸ“‹ ê¸°ë³¸ ì •ë³´ ë¹„êµ")
                    
                    comparison_data = pd.DataFrame({
                        file_options[compare_idx1]: [
                            len(df1),
                            len(df1.columns),
                            f"{df1.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB",
                            df1.isnull().sum().sum()
                        ],
                        file_options[compare_idx2]: [
                            len(df2),
                            len(df2.columns), 
                            f"{df2.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB",
                            df2.isnull().sum().sum()
                        ]
                    }, index=['í–‰ ìˆ˜', 'ì—´ ìˆ˜', 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰', 'ê²°ì¸¡ê°’ ìˆ˜'])
                    
                    st.dataframe(comparison_data)
                    
                    # ê³µí†µ ì»¬ëŸ¼ í™•ì¸
                    common_cols = set(df1.columns) & set(df2.columns)
                    if common_cols:
                        st.markdown(f"#### ğŸ”— ê³µí†µ ì»¬ëŸ¼ ({len(common_cols)}ê°œ)")
                        st.write(", ".join(sorted(common_cols)))
                    
                    # ì°¨ì´ì  ì»¬ëŸ¼
                    diff_cols1 = set(df1.columns) - set(df2.columns)
                    diff_cols2 = set(df2.columns) - set(df1.columns)
                    
                    if diff_cols1:
                        st.markdown(f"#### ğŸ”¸ {file_options[compare_idx1]} ê³ ìœ  ì»¬ëŸ¼")
                        st.write(", ".join(sorted(diff_cols1)))
                    
                    if diff_cols2:
                        st.markdown(f"#### ğŸ”¸ {file_options[compare_idx2]} ê³ ìœ  ì»¬ëŸ¼")
                        st.write(", ".join(sorted(diff_cols2)))
    
    # ì§ˆë¬¸ ì˜ˆì‹œ ìŠ¤íƒ€í„° (ì±„íŒ… ê¸°ë¡ì´ ì—†ì„ ë•Œë§Œ í‘œì‹œ)
    if not st.session_state.chat_history:
        st.markdown("### ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ (í´ë¦­í•˜ì—¬ ë°”ë¡œ ì‚¬ìš©í•˜ê¸°)")
        
        # í‚¤ì›Œë“œ ì•ˆë‚´ ë¬¸êµ¬
        st.info("ğŸ“Œ **íš¨ê³¼ì ì¸ ì§ˆë¬¸ì„ ìœ„í•œ í‚¤ì›Œë“œ ì•ˆë‚´**  \n"
                "ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì—¬ ì§ˆë¬¸í•˜ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  \n"
                "**ì‚¬ì—…ì‹¤**, **ê·¸ë£¹**, **íŒë§¤ëŸ‰**, **ë§¤ì¶œì•¡**, **ì˜ì—…ì´ìµ**, **ì„¸ì „ì´ìµ**, **ê³µê¸‰ì‚¬**, **ê³ ê°ì‚¬**, **êµ­ê°€**, **íŒë§¤ìœ í˜•(ì‚¼êµ­ê°„,ìˆ˜ì¶œ,ë‚´ìˆ˜)**")
        
        
        starter_examples = [
            "ì „ì²´ ì‚¬ì—…ì‹¤ì˜ ì´ ë§¤ì¶œ ìˆ˜ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ì „ì²´ ì‚¬ì—…ì‹¤ì˜ íŒë§¤ëŸ‰ê³¼ ì˜ì—…ì´ìµì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì „ì²´ ì‚¬ì—…ì‹¤ì˜ ì´ ë§¤ì¶œì•¡ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ë§¤ì¶œ ìˆ˜ëŸ‰ì´ ê°€ì¥ ë§ì€ ìƒìœ„ 5ê°œ ê·¸ë£¹ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì˜ì—…ì´ìµì´ ê°€ì¥ ë†’ì€ ì‚¬ì—…ì‹¤ì€ ì–´ë””ì¸ê°€ìš”?",
            "ì „ì²´ì‚¬ì—…ì‹¤ ì¤‘ì—ì„œ 'POSCO' ê³µê¸‰ì‚¬ì˜ ì´ ë§¤ì¶œìˆ˜ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "2023ë…„ ìƒë°˜ê¸° ì „ì²´ ë§¤ì¶œ ìˆ˜ëŸ‰ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "2023ë…„ì˜ ì˜ì—…ì´ìµì€ ì–¼ë§ˆì¸ê°€ìš”?",
        ]
        
        # ë‹¤ì¤‘ íŒŒì¼ì¼ ê²½ìš° ë¹„êµ ì§ˆë¬¸ ì˜ˆì‹œ ì¶”ê°€
        if len(st.session_state.uploaded_datasets) >= 2:
            comparison_examples = [
                "ë‘ íŒŒì¼ì˜ ì „ì²´ ë§¤ì¶œì•¡ì„ ë¹„êµí•´ì£¼ì„¸ìš”",
                "ê° íŒŒì¼ì˜ ìƒìœ„ 5ê°œ ì‚¬ì—…ì‹¤ ì˜ì—…ì´ìµì„ ë¹„êµë¶„ì„í•´ì£¼ì„¸ìš”",
                "íŒŒì¼ë³„ 2023ë…„ ë§¤ì¶œìˆ˜ëŸ‰ ì°¨ì´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                "ë‘ ë°ì´í„°ì…‹ì˜ ê³µê¸‰ì‚¬ë³„ ë§¤ì¶œ í˜„í™©ì„ ë¹„êµí•´ì£¼ì„¸ìš”",
            ]
            starter_examples.extend(comparison_examples)
        
        # ì§ˆë¬¸ ì˜ˆì‹œë¥¼ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ
        cols = st.columns(2)
        for i, example in enumerate(starter_examples):
            col = cols[i % 2]
            if col.button(f"ğŸ“ {example}", key=f"example_{i}", use_container_width=True):
                st.session_state.selected_question = example
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    if st.session_state.chat_history:
        st.markdown("### ğŸ’¬ ëŒ€í™” ê¸°ë¡")
        for i, chat in enumerate(st.session_state.chat_history):
            with st.container():
                # ì‚¬ìš©ì ì§ˆë¬¸
                with st.chat_message("user"):
                    st.markdown(chat["question"])
                
                # AI ë‹µë³€
                with st.chat_message("assistant"):
                    st.markdown(chat["answer"])
                    
                    # ìƒì„¸ ì •ë³´ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)
                    with st.expander(f"ğŸ“Š ìƒì„¸ ì •ë³´ #{i+1}", expanded=False):
                        # ìƒˆë¡œìš´ ë…¸ë“œë“¤ì˜ ì²˜ë¦¬ ê³¼ì • í‘œì‹œ
                        if chat.get("context_used", False):
                            st.markdown("#### ğŸ”„ Context Aware ì²˜ë¦¬:")
                            st.success(f"âœ… ì»¨í…ìŠ¤íŠ¸ í™œìš©: {chat.get('enhanced_input', 'ì •ë³´ ì—†ìŒ')}")
                        
                        intent_info = chat.get("intent_info", {})
                        query_plan = chat.get("query_plan", {})
                        
                        if intent_info:
                            st.markdown("#### ğŸ¯ Intent Classification ê²°ê³¼:")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ê°ì§€ëœ ì˜ë„", intent_info.get("intent", "general"))
                            with col2:
                                st.metric("ë³µì¡ë„", intent_info.get("complexity", "medium"))
                            with col3:
                                confidence = intent_info.get("confidence", 0)
                                st.metric("ì‹ ë¢°ë„", f"{confidence:.1%}")
                            
                            if intent_info.get("predicted_tools"):
                                st.markdown("**ì˜ˆì¸¡ëœ ë„êµ¬ë“¤:**")
                                tools_text = ", ".join(intent_info["predicted_tools"][:3])
                                st.text(tools_text)
                        
                        if query_plan:
                            st.markdown("#### ğŸ—‚ï¸ Query Planning ê²°ê³¼:")
                            execution_plan = query_plan.get("execution_plan", {})
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("ë¶„ì„ ì „ëµ", execution_plan.get("strategy", "unknown"))
                            with col2:
                                confidence = query_plan.get("confidence", 0)
                                st.metric("ê³„íš ì‹ ë¢°ë„", f"{confidence:.1%}")
                            
                            if query_plan.get("required_columns"):
                                st.markdown("**ê°ì§€ëœ ì»¬ëŸ¼ë“¤:**")
                                st.text(", ".join(query_plan["required_columns"]))
                            
                            if query_plan.get("detected_metrics"):
                                st.markdown("**ë¶„ì„ ì§€í‘œ:**")
                                st.text(", ".join(query_plan["detected_metrics"]))
                        
                        # ë°ì´í„° ì¶œì²˜
                        st.markdown("#### ğŸ“‹ ë°ì´í„° ì¶œì²˜:")
                        st.info(chat.get("source_info", "ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼"))
                        
                        # ê³„ì‚° ê³¼ì •
                        if chat.get("intermediate_steps"):
                            st.markdown("#### ğŸ”„ ê³„ì‚° ê³¼ì •:")
                            for j, step in enumerate(chat["intermediate_steps"], 1):
                                if isinstance(step, tuple) and len(step) >= 2:
                                    action, observation = step[0], step[1]
                                    st.markdown(f"**ë‹¨ê³„ {j}:** {action}")
                                    if observation:
                                        st.code(str(observation)[:300] + "..." if len(str(observation)) > 300 else str(observation))
                                else:
                                    st.markdown(f"**ë‹¨ê³„ {j}:** {str(step)}")
                        else:
                            st.markdown("#### ğŸ”„ ê³„ì‚° ê³¼ì •:")
                            st.info("ê¸°ë³¸ ì§‘ê³„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        
                        # ë°ì´í„° ìš”ì•½ ì •ë³´
                        st.markdown("#### ğŸ“ˆ ì°¸ê³ í•œ ë°ì´í„° ì •ë³´:")
                        
                        # ê¸°ë³¸ ì •ë³´
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ í–‰ ìˆ˜", f"{len(df):,}ê°œ")
                        with col2:
                            st.metric("ì´ ì»¬ëŸ¼ ìˆ˜", f"{len(df.columns)}ê°œ")
                        with col3:
                            st.metric("ì°¸ê³  ì‹œíŠ¸", sheet_name)
                        
                        # ì»¬ëŸ¼ ì •ë³´
                        st.markdown("**ğŸ“‹ í™œìš©í•œ ì£¼ìš” ì»¬ëŸ¼:**")
                        columns_info = []
                        for col in df.columns[:10]:  # ì²˜ìŒ 10ê°œ ì»¬ëŸ¼ë§Œ í‘œì‹œ
                            col_type = str(df[col].dtype)
                            if df[col].dtype in ['object']:
                                unique_count = df[col].nunique()
                                columns_info.append(f"â€¢ **{col}** (í…ìŠ¤íŠ¸, {unique_count}ê°œ ê³ ìœ ê°’)")
                            elif df[col].dtype in ['int64', 'float64']:
                                columns_info.append(f"â€¢ **{col}** (ìˆ«ì)")
                            else:
                                columns_info.append(f"â€¢ **{col}** ({col_type})")
                        
                        st.markdown("\n".join(columns_info))
                        
                        if len(df.columns) > 10:
                            st.markdown(f"*...ë° {len(df.columns) - 10}ê°œ ì¶”ê°€ ì»¬ëŸ¼*")
    
    # ìƒˆë¡œìš´ ì§ˆë¬¸ ì…ë ¥ ì˜ì—­
    st.markdown("---")
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    with st.container():
        # CSS to align button height with text input
        st.markdown("""
        <style>
        div[data-testid="stVerticalBlock"] > div:nth-child(2) > div > div > div > button {
            height: 2.5rem;
            margin-top: 1.5rem;
        }
        </style>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([4, 1])
        
        with col1:
            question = st.text_input(
                "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
                value=st.session_state.get('selected_question', ''),
                key="new_question_input",
                placeholder="ì˜ˆ: ì´ì „ ë‹µë³€ì—ì„œ ìŠ¤í…Œì¸ë¦¬ìŠ¤ ì‚¬ì—…ì‹¤ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œë ¤ì¤˜"
            )
        
        with col2:
            # Add some vertical spacing to align with label
            st.markdown("<div style='height: 1.5rem;'></div>", unsafe_allow_html=True)
            send_button = st.button("ğŸ’¬ ì „ì†¡", type="primary", use_container_width=True)
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.session_state.chat_history:
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", type="secondary"):
                st.session_state.chat_history = []
                st.session_state.selected_question = ""
                st.rerun()

    # ì§ˆë¬¸ ì²˜ë¦¬
    if (send_button and question) or (question and st.session_state.get('selected_question')):
        with st.spinner("LangGraph ì—ì´ì „íŠ¸ê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (Context Aware Nodeì—ì„œ ì‚¬ìš©)
                chat_context = []
                for chat in st.session_state.chat_history[-3:]:  # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                    chat_context.append(f"Q: {chat['question']}")
                    chat_context.append(f"A: {chat['answer']}")
                
                # LangGraph ì‹¤í–‰ - ë‹¤ì¤‘ ë°ì´í„°ì…‹ ì •ë³´ ì „ë‹¬
                current_df = None
                datasets_info = {}
                dataset_count = 0
                active_dataset_name = "ì—…ë¡œë“œëœ íŒŒì¼"
                
                # í˜„ì¬ í™œì„± ë°ì´í„°ì…‹ ì„¤ì •
                if st.session_state.active_dataset:
                    current_df = st.session_state.active_dataset['df']
                    active_dataset_name = st.session_state.active_dataset['name']
                elif hasattr(st.session_state, 'df_for_chat'):
                    current_df = st.session_state.df_for_chat
                
                if current_df is None:
                    st.error("ë¶„ì„í•  ë°ì´í„°ì…‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    st.stop()
                
                # ë‹¤ì¤‘ ë°ì´í„°ì…‹ ì •ë³´ ìˆ˜ì§‘
                if hasattr(st.session_state, 'uploaded_datasets') and st.session_state.uploaded_datasets:
                    # ëª¨ë“  ë°ì´í„°ì…‹ì„ datasets_infoì— í¬í•¨
                    for file_key, dataset_info in st.session_state.uploaded_datasets.items():
                        for sheet_name, df in dataset_info['sheets'].items():
                            dataset_name = f"{dataset_info['name']} - {sheet_name}"
                            datasets_info[dataset_name] = df
                    
                    # ì‹¤ì œ ì‹œíŠ¸ ê°œìˆ˜ë¡œ ì¹´ìš´íŠ¸ (ë” ì •í™•)
                    dataset_count = len(datasets_info)
                else:
                    dataset_count = 1
                    datasets_info[active_dataset_name] = current_df
                
                # ë‹¤ì¤‘ íŒŒì¼ ì—¬ë¶€ ê²°ì •
                is_multi_dataset = dataset_count > 1
                
                print(f"ë°ì´í„°ì…‹ ìˆ˜: {dataset_count}, ë‹¤ì¤‘ íŒŒì¼: {is_multi_dataset}")
                print(f"í™œì„± ë°ì´í„°ì…‹: {active_dataset_name}")
                print(f"ì „ì²´ ë°ì´í„°ì…‹: {list(datasets_info.keys())}")
                
                # LangGraph ìƒíƒœì— ë‹¤ì¤‘ ë°ì´í„°ì…‹ ì •ë³´ ì „ë‹¬
                result = graph_executor.invoke({
                    "input": question, 
                    "df": current_df,
                    "chat_history": chat_context,
                    # ë‹¤ì¤‘ ë°ì´í„°ì…‹ ê´€ë ¨ ì •ë³´
                    "datasets_info": datasets_info,
                    "dataset_count": dataset_count,
                    "is_multi_dataset": is_multi_dataset,
                    "active_dataset_name": active_dataset_name
                })
                
                # ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€ (Phase 1 ë…¸ë“œ ì •ë³´ í¬í•¨)
                chat_entry = {
                    "question": question,
                    "answer": result['output'],
                    "source_info": result.get('source_info', 'ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼'),
                    "intermediate_steps": result.get('intermediate_steps', []),
                    # Phase 1 ë…¸ë“œ ì •ë³´
                    "enhanced_input": result.get('enhanced_input', question),
                    "context_used": result.get('context_used', False),
                    "intent_info": result.get('intent_info', {}),
                    "query_plan": result.get('query_plan', {}),
                    "processing_path": result.get('processing_path', 'agent_node')
                }
                st.session_state.chat_history.append(chat_entry)
                
                # ì„ íƒëœ ì§ˆë¬¸ ì´ˆê¸°í™”
                st.session_state.selected_question = ""
                
                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                st.rerun()
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.error("ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")